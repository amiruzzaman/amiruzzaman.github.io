{
  "Part 0": {
    "title": "Requirements:",
    "problems": [
      [
        {
          "yes": "The README is present on Canvas and you provided your steps, and your implementation is accessible. .",
          "no": "There is no README file or not accessible.",
          "point": 5
        },
        {
          "yes": "You provided your Overleaf link for your report.",
          "no": "You did not provide your Overleaf link for your report.",
          "point": 1
        },
        {
          "yes": "You have provided final GitHub commit for your repo.",
          "no": "Your submission is missing final GitHub commit for your repo.",
          "point": 1
        },
        {
          "yes": "You used proper referencing style.",
          "no": "You did not follow proper referencing style.",
          "point": 1
        },
        {
          "yes": "Your graphs/figures are readable.",
          "no": "Your graphs/figures are not readable.",
          "point": 1
        },
        {
          "yes": "Also, your report is 8 pages.",
          "no": "Also, your report is ... pages.",
          "point": 1
        }
      ]
    ]
  },
  "Part 1": {
    "title": "MDP Overview and Discretization:",
    "problems": [
      [
        {
          "yes": "You defined state space, action (hit or stick), reward structure (+1 for win, 0 for tie/draw, and -1 for loss), terminal state.",
          "no": "You needed to define state space, actions (hit or stick), reward structure (+1 for win, 0 for tie/draw, and -1 for loss), and terminal state.",
          "point": 5
        },
        {
          "yes": "You also defined state variables, action space, reward, and terminal conditions.",
          "no": "You did not define the state variables, action space, reward, or terminal conditions.",
          "point": 5
        },
        {
          "yes": "You highlighted key differences (Blackjack: small/discrete; CartPole: large/continuous), provided implications, described discretization approach (bins, rounding methods), and justified tradeoffs between fidelity and computational cost.",
          "no": "You did not highlight key differences (e.g., Blackjack: small/discrete; CartPole: large/continuous), nor did you discuss the implications, describe the discretization approach (bins, rounding methods), or justify tradeoffs between fidelity and computational cost.",
          "point": 5
        }
      ]
    ]
  },
  "Part 2": {
    "title": "Value Iteration and Policy Iteration:",
    "problems": [
      [
        {
          "yes": "For VI you described Bellman optimality, for PI explained policy evaluation and improvement steps, mentioned convergence guarantees, and articulated difference between VI and PI.",
          "no": "You did not describe the Bellman optimality equation for Value Iteration, explain the policy evaluation and improvement steps for Policy Iteration, mention convergence guarantees, or articulate the differences between VI and PI.",
          "point": 8
        },
        {
          "yes": "Provided vocalization for VI on Blackjack, PI on Blackjack, VI on Cartpole, and PI on Cartpole.",
          "no": "You did not provide vocalization for Value Iteration on Blackjack, Policy Iteration on Blackjack, Value Iteration on CartPole, or Policy Iteration on CartPole.",
          "point": 8
        },
        {
          "yes": "You tested hyperparameters, discussed PI's faster convergence, reported number of iterations with convergence criteria, and included quantitative and qualitative comparison.",
          "no": "You did not test hyperparameters, discuss Policy Iteration’s faster convergence, report the number of iterations with convergence criteria, or include a quantitative and qualitative comparison.",
          "point": 7
        },
        {
          "yes": "You stated whether VI and PI policies are the same, provided reasons for differences explained (if applicable), and used visualization.",
          "no": "You did not state whether the policies from Value Iteration and Policy Iteration are the same, did not explain possible reasons for any differences, and did not include visualizations.",
          "point": 4
        },
        {
          "yes": "In addition, you discussed discretization errors and explored tradeoffs (finer binning vs. runtime/memory).",
          "no": "You did not discuss discretization errors or explore tradeoffs between finer binning and runtime/memory usage.",
          "point": 3
        }
      ]
    ]
  },
  "Part 3": {
    "title": "SARSA and Q-Learning:",
    "problems": [
      [
        {
          "yes": "You provided correct definitions, clear explanation of on/off-policy, exploration implications, behavioral differences.",
          "no": "You did not provide correct definitions or a clear explanation of on-policy vs. off-policy methods, their exploration implications, or behavioral differences.",
          "point": 6
        },
        {
          "yes": "Also, you provided SARSA on Blackjack: Line plot of cumulative reward per episode, provided some discussion on Q-Learning on Blackjack: Same as SARSA, SARSA on CartPole: Line plot of episode length or reward, and Q-Learning on CartPole: Same as SARSA.",
          "no": "You did not provide SARSA results on Blackjack (e.g., line plot of cumulative reward per episode), did not include discussion or plots for Q-Learning on Blackjack, and did not present SARSA or Q-Learning results on CartPole (e.g., episode length or reward plots).",
          "point": 8
        },
        {
          "yes": "Your report included at least one strategy used (e.g., epsilon-greedy with decay), values or decay schedules, hyperparameter differences (3+ values), and impact on convergence.",
          "no": "Your report did not include at least one strategy used (e.g., epsilon-greedy with decay), values or decay schedules, hyperparameter differences (3+ values), or the impact on convergence.",
          "point": 7
        },
        {
          "yes": "Your report also included explicit comparison, key distinctions highlighted, reasoning rooted in theory.",
          "no": "Your report did not include an explicit comparison, highlight key distinctions, or provide reasoning rooted in theory.",
          "point": 6
        },
        {
          "yes": "Clear comparison, identifies reasons for mismatches, visual comparisons included. ",
          "no": "Your report did not include a clear comparison, identify reasons for mismatches, or provide visual comparisons.",
          "point": 6
        }
      ]
    ]
  },
  "Part 4": {
    "title": "Reflection and Integration:",
    "problems": [
      [
        {
          "yes": "You have some discussion on specific challenges, detailed discussion, actionable improvements.",
          "no": "We wanted to see some discussion on specific challenges, detailed discussion, actionable improvements.",
          "point": 6
        },
        {
          "yes": "Your report also include synthesized findings, reference data, interpretation of plots, connects to theory.",
          "no": "In addition, your report did not include synthesized findings, reference data, interpretation of plots, connects to theory.",
          "point": 6
        }
      ]
    ]
  },
  "Part 5": {
    "title": "Extra Credit:",
    "problems": [
      [
        {
          "yes": "DDPG or SAC implemented. ",
          "no": "No implementation for the extra credit.",
          "point": 5
        }
      ]
    ]
  }
}